{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Semantic Modelling with owlready2\n",
    "\n",
    "In this script, I import an ontology baseline I created in Protégé and add corresponding instances to it. Moreover, I query data from Geonames to add more information to the data basis. For doing the same for the Sachindex, I created another [script](enriching_database.ipynb) that can be used beforehand. The baseline ontology can be found in the data directory in the ``owl/baseline`` folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "import geocoder\n",
    "import pandas as pd\n",
    "from owlready2 import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "onto = get_ontology(\"../data/owl/baseline/cds-ontology.owl\").load()\n",
    "\n",
    "gndo = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://d-nb.info/gnd/\",\n",
    "    name=\"gndo\"\n",
    ")\n",
    "\n",
    "cds_docs = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://constance-de-salm.de/archiv/#/document/\",\n",
    "    name=\"cds_docs\"\n",
    ")\n",
    "\n",
    "gn = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://www.geonames.org/\",\n",
    "    name=\"gn\"\n",
    ")\n",
    "\n",
    "viaf = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://viaf.org/viaf/\",\n",
    "    name=\"viaf\"\n",
    ")\n",
    "\n",
    "wikidata = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://www.wikidata.org/wiki/\",\n",
    "    name=\"wikidata\"\n",
    ")\n",
    "\n",
    "gn_onto = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"https://www.geonames.org/ontology#\",\n",
    "    name=\"gn_onto\"\n",
    ")\n",
    "\n",
    "dbo = Namespace(\n",
    "    world_or_ontology=onto,\n",
    "    base_iri=\"http://dbpedia.org/ontology/\",\n",
    "    name=\"dbo\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Individuals are instances in ontologies. They are created as any other Python instances. The first parameter is the name (or identifier) of the Individual; it corresponds to the .name attribute in Owlready2. If not given, the name if automatically generated from the Class name and a number.\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Individuals are instances in ontologies. They are created as any other Python instances. The first parameter is the name (or identifier) of the Individual; it corresponds to the .name attribute in Owlready2. If not given, the name if automatically generated from the Class name and a number.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Parsing CSV file as DataFrame in order to create individuals.\n",
    "\n",
    "df = pd.read_csv('../data/retrieved/cds_cleanup.csv')\n",
    "df = df.fillna(0)\n",
    "df['Geonames (Ausstellungsort)'] = df['Geonames (Ausstellungsort)'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sachindex = pd.read_csv('../data/retrieved/sachindex_additional_data_completed-v2.csv', sep=\";\")\n",
    "sachindex = sachindex.drop(columns='Unnamed: 0', axis=1)\n",
    "sachindex = sachindex.fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_geodata(dataframe: pd.DataFrame, feature_column: str) -> None:\n",
    "    for feature in dataframe[feature_column].unique():\n",
    "        if feature != 0:\n",
    "            g = geocoder.geonames(\n",
    "                str(feature),\n",
    "                method='details',\n",
    "                geoNamesUsername=\"sarahondraszek\",\n",
    "                key=\"sarahondraszek\"\n",
    "            )\n",
    "            t_g = gn_onto.Feature(\n",
    "                str(feature),\n",
    "                namespace=gn\n",
    "            )\n",
    "            t_g.lat.append(g.lat)\n",
    "            t_g.long.append(g.lng)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "get_geodata(df, 'Geonames (Ausstellungsort)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_topic(indicator: str, w: str, substitue: str = '', e: str ='') -> onto.Topic:\n",
    "    if indicator == \"own\":\n",
    "        t = onto.Topic(\n",
    "            \"t_\"+str(int(sachindex[sachindex['Deutsch']==w].index[0])),\n",
    "            namespace=onto\n",
    "        )\n",
    "        t.label = [locstr(w, lang =\"de\")]\n",
    "    elif indicator == \"wikidata\":\n",
    "        t = onto.Topic(\n",
    "            re.sub(\n",
    "                substitue,\n",
    "                '',\n",
    "                e\n",
    "            ),\n",
    "            namespace=wikidata\n",
    "        )\n",
    "        t.label = [locstr(w, lang =\"de\")]\n",
    "\n",
    "    return t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_letter(input_url: str, idx: int, dataframe: pd.DataFrame, ns: Namespace) -> onto.Letter:\n",
    "    l = onto.Letter(re.sub(cds_docs.base_iri, '', input_url), namespace=ns)\n",
    "    l.fud_key = dataframe['FuD-Key'][idx]\n",
    "    l.has_year.append(int(dataframe['year'][idx]))\n",
    "    l.has_decade.append(int(dataframe['decade'][idx]))\n",
    "    l.has_date.append(str(dataframe['Datierung (JJJJ-MM-TT)'][idx]))\n",
    "\n",
    "    return l"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_sender_properties(instnc: onto.Sender, dataframe: pd.DataFrame, idx: int, indicator: str) -> None:\n",
    "    #lbl = dataframe[indicator][idx].split(',')\n",
    "    #lbl = (lbl[1] + ' ' + lbl[0]).strip()\n",
    "    instnc.label = [locstr(dataframe[indicator][idx], lang =\"en\")]\n",
    "    instnc.has_viaf = viaf.base_iri + str(dataframe[f'VIAF ({indicator})'][idx])\n",
    "    instnc.has_wikidata = dataframe[f'Wikidata-Identifier ({indicator})'][idx]\n",
    "    for alt_names in dataframe[f'Alternativer Name ({indicator})'][idx].split(';'):\n",
    "        instnc.alias.append(alt_names.strip())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Adding instances of the CdS letters with senders and addressees, topics and places of exposition.\n",
    "index = 0\n",
    "for url in df['URL']:\n",
    "    # Adding new letter to ontology.\n",
    "    new_letter = create_letter(input_url=url, idx=index, dataframe=df, ns=cds_docs)\n",
    "    # Adding sender to ontology.\n",
    "    new_sender = onto.Sender(df['GND (Verfasser)'][index], namespace=gndo)\n",
    "    # Add properties to sender.\n",
    "    add_sender_properties(instnc=new_sender, dataframe=df, idx=index, indicator=\"Verfasser\")\n",
    "    # Append sender to letter.\n",
    "    new_letter.has_sender.append(new_sender)\n",
    "\n",
    "    # Adding receiver to ontology.\n",
    "    if df['GND (Empfänger)'][index] == 0 and df['VIAF (Empfänger)'][index] != 0:\n",
    "        new_addressee = onto.Addressee(df['VIAF (Empfänger)'][index], namespace=viaf)\n",
    "    elif df['GND (Empfänger)'][index] == 0 and df['VIAF (Empfänger)'][index] == 0:\n",
    "        if not type(df['Empfänger'][index]) is int:\n",
    "            l = df['Empfänger'][index].split(',')\n",
    "            if len(l) > 1:\n",
    "                new_addressee = onto.Addressee((re.sub(r\"[^a-zA-Z]+\", '', l[0])+'_'+re.sub(r\"[^a-zA-Z]+\", '', l[1])).lower(), namespace=onto)\n",
    "            else:\n",
    "                new_addressee = onto.Addressee(\n",
    "                    re.sub(\n",
    "                        r\"[^a-zA-Z]+\", '', re.sub(\n",
    "                            ' +', '_', df['Empfänger'][index]\n",
    "                        ).lower()\n",
    "                    ),\n",
    "                    namespace=onto\n",
    "                )\n",
    "        else:\n",
    "            new_addressee = onto.Addressee('0', namespace=onto)\n",
    "    else:\n",
    "        new_addressee = onto.Addressee(df['GND (Empfänger)'][index], namespace=gndo)\n",
    "        if not df['VIAF (Empfänger)'][index] == 0:\n",
    "            new_addressee.has_viaf = viaf.base_iri + str(df['VIAF (Empfänger)'][index])\n",
    "\n",
    "\n",
    "    if not type(df['Empfänger'][index]) is int:\n",
    "        l = df['Empfänger'][index].split(',')\n",
    "        if len(l) > 1:\n",
    "            label = re.sub(\n",
    "                '\\s+',' ', re.sub(\n",
    "                    r'(\\([^)]*(CdS|Bruder|SRD|Neffe|Siehe|Tochter|Anwältin|Rechtsanwalt)[^)]*\\)*)','',(l[1]+' '+l[0])\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            label = df['Empfänger'][index]\n",
    "        new_addressee.label = [locstr(label.strip(), lang = \"en\")]\n",
    "    else:\n",
    "        new_addressee.label = 0\n",
    "\n",
    "    # Add wikidata.\n",
    "    if not type(df['Wikidata-Identifier (Empfänger)'][index]) == int:\n",
    "        new_addressee.has_wikidata = df['Wikidata-Identifier (Empfänger)'][index]\n",
    "\n",
    "    # Add alias.\n",
    "    if not type(df['Alternativer Name (Empfänger)'][index]) == int:\n",
    "        for names in df['Alternativer Name (Empfänger)'][index].split(';'):\n",
    "            new_addressee.alias.append(names.strip())\n",
    "    # Appending receiver to letter.\n",
    "    new_letter.has_addressee.append(new_addressee)\n",
    "\n",
    "    # Adding topics to ontology and appending them to the letter.\n",
    "    if df['Schlagwörter'][index] == 0:\n",
    "        empty_topic = onto.Topic(\"t0\", namespace=onto)\n",
    "        empty_topic.label = \"Empty Topic\"\n",
    "        new_letter.has_topic.append(empty_topic)\n",
    "    else:\n",
    "        for keyword_list in df['Schlagwörter'][index].split(\";\"):\n",
    "            for keyword in keyword_list.split(\";\"):\n",
    "                l = [word.strip() for word in keyword.split('/')]\n",
    "                for word in l:\n",
    "                    try:\n",
    "                        w_i = 0\n",
    "                        entry = sachindex.loc[sachindex['Deutsch'] == word]['Wikidata'].values[0]\n",
    "                        if entry == 0:\n",
    "                            new_topic = create_topic(indicator=\"own\", w=word)\n",
    "                            new_letter.has_topic.append(new_topic)\n",
    "                        else:\n",
    "                            new_topic = create_topic(substitue=wikidata.base_iri, w=word, e=entry, indicator=\"wikidata\")\n",
    "                            new_letter.has_topic.append(new_topic)\n",
    "                        w_i += 1\n",
    "                    except ValueError and IndexError:\n",
    "                        continue\n",
    "\n",
    "    if df['Geonames (Ausstellungsort)'][index] != 0:\n",
    "        for x in gn_onto.Feature.instances():\n",
    "            if x.iri == df['Geonames (Ausstellungsort)'][index]:\n",
    "                new_letter.has_place_of_exposition.append(x)\n",
    "\n",
    "\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "onto.save(file = \"../data/owl/cds_onto_extended.owl\", format = \"rdfxml\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
